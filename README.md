# Forecasting Stock Market Trends with NLP

Mentor: Raiden Han (dhan5@ncsu.edu)

Group Members: Param Arunachalam (parunac@ncsu.edu), Sameer Shaik (snallav@ncsu.edu), Zongxin Tian (tzongxi@ncsu.edu), Shuhan Yang (syang36@ncsu.edu)


## Weekly Meetings Information

**Time: 2:00-3:00 pm Monday EST**

:deciduous_tree: [Join Zoom Meeting](https://ncsu.zoom.us/j/91496732888?pwd=a3pnVDFKeWRWbW9pcElWQkllWjI3dz09)

Meeting ID: 914 9673 2888

Passcode: 885850

## Schedule

|           Time          |                                        Contents                                       |
|:------------------------|:--------------------------------------------------------------------------------------|
| Week 1 (01/23 - 01/29)  | Introduction to Git, Github and Functional Programming                                |
| Week 2 (01/30 - 02/05)  | Natural Language Preprocessing: Tokenizing, Stop Words and Stemming                   |
| Week 3 (02/06 - 02/12)  | Naïve Bayes Model                                                                     |
| Week 4 (02/13 - 02/19)  | Vector Space Model, PCA, Approx. KNN and Cosine Similarity; **Deliverable #1 Due**    |
| Week 5 (02/20 - 02/26)  | N-gram Model (Bag-of-Words Model) and Machine Learning Models; **Deliverable #2 Due** |
| Week 6 (02/27 - 03/05)  | TF-IDF Model                                                                          |
| Week 7 (03/06 - 03/12)  | *Break for Midterms (No Meeting)*                                                     |
| Week 8 (03/13 - 03/19)  | *Spring Break (No Meeting)*; **Deliverable #3 Due**                                   |
| Week 9 (03/20 - 03/26)  | Practice for the Final Presentation; **Deliverable #4 Due**                           |
| Week 10 (03/27 - 04/02) | Practice for the Final Presentation                                                   |


## Deliverables

:exclamation: For each deliverable, codes, report, and slides are **all required**

### Deliverable #1 (Due in Week 4)

- Collect, Merge and Understand datasets
- Preprocessing to extract the key information from datasets and explain the logic

### Deliverable #2 (Due in Week 5)

- Construct, train, and test the Naïve Bayes model
- Filter words by the ratio of positive to negative counts and analyze them
- Understand the assumption behind the model and implement error analysis

### Deliverable #3 (Due in Week 8)

- Learn differences between Word by Word and Word by Doc
- Learn the advantage of cosine similarity compared to Euclidean distance
- Understand the methodology behind the approximate K-nearest neighbors method
- Use the pre-trained GoogleNews vectors dataset to construct the vector space model and predict trends
- Apply PCA Algorithm for data analysis and data visualization

### Deliverable #4 (Due in Week 9)

- Use the N-gram model (and the TF-IDF model) to vectorize the document
- Understand pros and cons of the vectorization model(s)
- Compare results from different basic machine learning models
